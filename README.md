<br>

<img align="left" width="90" height="90" src="https://github.com/exercism/website-icons/blob/main/tracks/python.svg">
<p vertical-align="middle"><h1>Python Web Scrayping</h1></p>

<br>

![Exercism_II](https://img.shields.io/badge/Exercism--Built-9101FF?logo=python&logoColor=FFDF58&labelColor=3D7AAB&label=Python-Powered)
![Twitter](https://img.shields.io/twitter/follow/cooon0201?label=Follow&style=social)
![Contributors](https://img.shields.io/github/contributors/COOONinc/Scrayping)

<h4 align = "justify"> This repository gives to enough knowledge about python web scrayping !!! </h4>

# What is scraping?
> Web scraping is a computer software technique for extracting information from websites.


![gif](https://user-images.githubusercontent.com/63713624/142664151-3e8cb392-5996-4814-97d9-47c8507291ff.gif)


# Installation tools


#### Below are some tools that you can download before getting started with Python, now itâ€™s a preference, so download whichever that fits the best for you.

| Name of the tools | 
| ------------- |
|[Python download](https://www.python.org/downloads/)|
|[Visual Studio Code](https://code.visualstudio.com/download)|
|[Jupyter Notebook](https://jupyter.org/install)|
|[Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb)|

> I personally use Google Colab for python programming. It's one of the best interactive tool in the world. I like it because I can provide more documentation to the code and write some quality tutorials.</p>

## Setup

1. Install [`pip` and `virtualenv`](https://cloud.google.com/python/docs/setup) if you do not already have them.

2. Clone this repository:

    ```
    git clone https://github.com/COOONinc/Scrayping.git
    ```
3. Install Library

    Install the necessary libraries.
    ```
    pip install -r requirements.txt
    ```
    [chromedriver-binary](https://pypi.org/project/chromedriver-binary/)
    
    [gspread](https://docs.gspread.org/en/latest/)
    
    [googleapis/oauth2client](https://github.com/googleapis/oauth2client)
    
4. create your serviceAccount.json

   `credentials = ServiceAccountCredentials.from_json_keyfile_name('serviceAccount.json', scope)`
5. create your google sparedsheet && get key from it

   `SPREADSHEET_KEY = ''`
6. setting site URL you want to scrayping 
  
   `driver.act('')`
